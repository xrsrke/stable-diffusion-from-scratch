# from foundation.transformer.attention import Attention


# def test_scaled_dot_product_attention():
#     pass