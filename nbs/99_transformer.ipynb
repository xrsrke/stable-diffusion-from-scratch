{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6096f92-15ea-4c5e-be15-59d8bcf36e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ffaaf-2b17-4420-9619-7877756039f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_heads, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        # Define the sublayers of the encoder layer\n",
    "        self.self_attention = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
    "\n",
    "        # Define the layer normalization and dropout layers\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src_seq):\n",
    "        # Apply the self-attention sublayer\n",
    "        attn_output = self.self_attention(src_seq, src_seq, src_seq)\n",
    "\n",
    "        # Apply the dropout and layer normalization to the self-attention output\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        attn_output = self.layer_norm1(attn_output)\n",
    "\n",
    "        # Add the self-attention output to the input sequence\n",
    "        src_seq = src_seq + attn_output\n",
    "\n",
    "        # Apply the feed-forward sublayer\n",
    "        ffn_output = self.feed_forward(src_seq)\n",
    "\n",
    "        # Apply the dropout and layer normalization to the feed-forward output\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        ffn_output = self.layer_norm2(ffn_output)\n",
    "\n",
    "        # Add the feed-forward output to the input sequence\n",
    "        src_seq = src_seq + ffn_output\n",
    "\n",
    "        # Return the encoded input sequence\n",
    "        return src_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda18ec0-faf0-4a9a-b88c-95b0372f09c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_heads, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        # Define the sublayers of the decoder layer\n",
    "        self.self_attention = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.multi_head_attention = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
    "\n",
    "        # Define the layer normalization and dropout layers\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src_seq, tgt_seq):\n",
    "        # Apply the self-attention sublayer to the target sequence\n",
    "        attn_output = self.self_attention(tgt_seq, tgt_seq, tgt_seq)\n",
    "\n",
    "        # Apply the dropout and layer normalization to the self-attention output\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        attn_output = self.layer_norm1(attn_output)\n",
    "\n",
    "        # Add the self-attention output to the target sequence\n",
    "        tgt_seq = tgt_seq + attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c0890-41f1-4bcd-afe0-fe68b905064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, d_ff, num_heads, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # Define the encoder and decoder layers\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, d_ff, num_heads, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, d_ff, num_heads, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Define the positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "\n",
    "    def forward(self, src_seq, tgt_seq):\n",
    "        # Encode the input sequence\n",
    "        encoded = self.encode(src_seq)\n",
    "\n",
    "        # Decode the output sequence\n",
    "        decoded = self.decode(encoded, tgt_seq)\n",
    "\n",
    "        # Return the decoded output sequence\n",
    "        return decoded\n",
    "\n",
    "    def encode(self, src_seq):\n",
    "        # Add the positional encoding to the input sequence\n",
    "        src_seq = self.positional_encoding(src_seq)\n",
    "\n",
    "        # Apply the encoder layers to the input sequence\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            src_seq = encoder_layer(src_seq)\n",
    "\n",
    "        # Return the encoded sequence\n",
    "        return src_seq\n",
    "\n",
    "    def decode(self, src_seq, tgt_seq):\n",
    "        # Add the positional encoding to the target sequence\n",
    "        tgt_seq = self.positional_encoding(tgt_seq)\n",
    "\n",
    "        # Apply the decoder layers to the target sequence\n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            tgt_seq = decoder_layer(src_seq, tgt_seq)\n",
    "\n",
    "        # Return the decoded sequence\n",
    "        return tgt_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69212508-3f9f-4ea5-ae78-7f9ad7a11f7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultiHeadAttention' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m dropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Instantiate the transformer model\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_ff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Define the optimizer and the learning rate\u001b[39;00m\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "Cell \u001b[0;32mIn [8], line 6\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[0;34m(self, num_layers, d_model, d_ff, num_heads, dropout)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28msuper\u001b[39m(Transformer, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Define the encoder and decoder layers\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_layers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[1;32m      7\u001b[0m     EncoderLayer(d_model, d_ff, num_heads, dropout)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers)\n\u001b[1;32m      9\u001b[0m ])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_layers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[1;32m     11\u001b[0m     DecoderLayer(d_model, d_ff, num_heads, dropout)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers)\n\u001b[1;32m     13\u001b[0m ])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Define the positional encoding\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [8], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28msuper\u001b[39m(Transformer, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Define the encoder and decoder layers\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_layers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mEncoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_ff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers)\n\u001b[1;32m      9\u001b[0m ])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_layers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[1;32m     11\u001b[0m     DecoderLayer(d_model, d_ff, num_heads, dropout)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers)\n\u001b[1;32m     13\u001b[0m ])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Define the positional encoding\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [6], line 6\u001b[0m, in \u001b[0;36mEncoderLayer.__init__\u001b[0;34m(self, d_model, d_ff, num_heads, dropout)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28msuper\u001b[39m(EncoderLayer, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Define the sublayers of the encoder layer\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attention \u001b[38;5;241m=\u001b[39m \u001b[43mMultiHeadAttention\u001b[49m(d_model, num_heads, dropout)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward \u001b[38;5;241m=\u001b[39m FeedForward(d_model, d_ff, dropout)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Define the layer normalization and dropout layers\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MultiHeadAttention' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters of the model\n",
    "d_model = 512\n",
    "d_ff = 2048\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "dropout = 0.1\n",
    "\n",
    "# Instantiate the transformer model\n",
    "model = Transformer(d_model, d_ff, num_heads, num_layers, dropout)\n",
    "\n",
    "# Define the optimizer and the learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the transformer model\n",
    "for epoch in range(10):\n",
    "    # Iterate over the training data in batches\n",
    "    for src_seq, tgt_seq in train_dataloader:\n",
    "        # Forward pass through the model\n",
    "        output = model(src_seq, tgt_seq)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(output, tgt_seq)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass through the model\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the model parameters\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d726f-d815-4e05-a1f4-87047cdfe217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb-from-scratch",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
