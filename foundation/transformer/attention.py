# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/07_transformer.attention.ipynb.

# %% auto 0
__all__ = ['A', 'MultiHeadAttention']

# %% ../../nbs/07_transformer.attention.ipynb 7
class A:
    pass

# %% ../../nbs/07_transformer.attention.ipynb 15
class MultiHeadAttention(nn.Module):
    def __init__(
        self,
        heads: int,
        d_model: int,
        dropout_prop: float=0.1,
        bias: bool = True
    ):
        super().__init__()
        self.d_k = d_model // heads
        self.heads = heads
        self.query = PrepareForMultiHeadAttention(d_model, heads, self.d_k, bias)
