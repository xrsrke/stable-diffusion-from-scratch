{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c3444a-7a45-44bd-81d9-fedb5e3c00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8949c35-dc31-480a-8863-4be8d571211e",
   "metadata": {},
   "source": [
    "### ResidualLayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1315e978-5942-4667-ade4-cde3700263f4",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f2838b6-57a9-4b62-9b58-ebe567cee9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, sentence_length, embedding_dim = 20, 5, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "013c62d9-0e6b-43c1-a4a0-5e2b7132f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.randn(batch, sentence_length, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c72e899d-435d-41ad-88b0-59b536153844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d48788-a8e8-406d-beb5-a29ec22e321d",
   "metadata": {},
   "source": [
    "`embedding` is a text embedding of a batch of `20` sentences, each sentence contain `5` words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e1b6211-188c-4a38-901c-7c7340e5f5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 5, 10])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb862db-ce66-4a9a-a232-68fbfea0fa35",
   "metadata": {},
   "source": [
    "Apply Layer Norm to `embedding` using Pytorch's built-in module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a71cb328-90f3-4b72-88d3-71a29a214d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = embedding.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "326a86ce-fff0-45b3-ace8-a355521c0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norm = nn.LayerNorm(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f753fe8-f873-4a67-a221-aa01364ca0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = layer_norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b9c7bb4-51fd-4383-9f70-0e47a4590fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 5, 10])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a991e60-61f3-497d-a0a7-9a33269d61e9",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62fbd9c5-251e-4b83-a9db-4e2d2db31d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_attention = torch.randn(10, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb6945dc-2ef5-467c-894d-2e3545b7f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.randn(10, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e50840d4-bfb3-4b9c-b338-441e9b8232fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9ec5351a-f40f-4b26-87c2-5c0e98a7b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualLayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, dropout):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, residual):\n",
    "        # source: git/hyunwoongko/transformer/blob/\n",
    "        # master/models/blocks/encoder_layer.py\n",
    "        return self.layer_norm(self.dropout(x) + residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ad9e38-9112-4c43-9b3e-3d59472f1e6f",
   "metadata": {},
   "source": [
    "`output_attention` is the output of the first multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05f55c6-4bc7-48c1-92b0-235a6b721662",
   "metadata": {},
   "source": [
    "`embeddings` is the text embedding of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cdb2c65e-fcbf-4288-822f-e42b176266ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 3, 5]), torch.Size([10, 3, 5]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_attention.shape, embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7676dcc7-2603-4995-8748-4edc13fa5604",
   "metadata": {},
   "source": [
    "`ResidualLayerNorm` is the first layer norm in Encoder Block. Write it from scratch\n",
    "\n",
    "**Hint**: Allow use Pytorch's built-in module for `LayerNorm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cf789cef-9f64-42bc-8e05-cca430dd36cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = ResidualLayerNorm(d_model=5, dropout=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "50f7d356-0aee-4f91-9088-72d3ce5e56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = layer(\n",
    "    x=output_attention,\n",
    "    residual=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5ee15933-1ec1-4281-bf43-1439d746c088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8e4989-92b8-4fb7-a1be-16407300eca1",
   "metadata": {},
   "source": [
    "### Position-wise Feed Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4b2eb9-d797-4c7f-8939-9fc4637f826e",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c77ba12b-b52e-4659-862f-e3fe78b6a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d35bdfe2-2b3a-4ce1-b337-539d43549738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2eb26cca-2c8e-41d9-87ae-d5454c111e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # shape(x) = [batch_size x seq_len x d_model]\n",
    "        \n",
    "        # shape(output) = [batch_size x seq_len x d_model]\n",
    "        output = self.layers(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c8c122-5af1-4566-b53e-47c7d52c1409",
   "metadata": {},
   "source": [
    "`x` is the ouput of the `Add & Norm` layer in Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "19f7cb71-83f6-4649-9f4e-897b75f24841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e04fc3d-9653-47c5-a27c-d238e0eea366",
   "metadata": {},
   "source": [
    "Write a Position-wise Feed Forward layer from scratch\n",
    "\n",
    "**Hint**: Allow use Pytorch's Dropout module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "98209662-1881-472e-b77b-c0b648ffe682",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = PostionWiseFeedForward(\n",
    "    d_model=5,\n",
    "    d_ff=16,\n",
    "    dropout=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c4468643-c06b-48cb-a602-8a44dc4cb29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "71ebc03b-f80d-4557-9d2f-fafe88e38893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c190f7-3167-4bea-9041-765352646784",
   "metadata": {},
   "source": [
    "### Encoder Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29f8a9-c611-4c18-81aa-68491939a3ae",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "035e357e-cd15-477f-9f82-c6fdf9c8b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.randn(5, 3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64eab5f-9704-4c1a-a43a-360371697be6",
   "metadata": {},
   "source": [
    "Given\n",
    "- `ResidualLayerNorm`\n",
    "    + Take `d_model` and `dropout` in initialize\n",
    "    + Take `x` and `residual` in forward pass\n",
    "- `PostionWiseFeedForward`\n",
    "    + Take `d_model`, `d_ff` and `dropout` in initialize\n",
    "    + Take `x` in forward pass\n",
    "- `MultiHeadAttention`\n",
    "    + Take `d_model` and `n_heads`in initialize\n",
    "    + Take `pre_q`, `pre_k`, and `pre_v` in forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cb32ef6a-37bd-40c5-b1e9-fd126c306323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from foundation.transformer.encoder import ResidualLayerNorm, PostionWiseFeedForward\n",
    "from foundation.transformer.efficient_attention import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dd6f76-e24b-419f-9140-75e930cfeab5",
   "metadata": {},
   "source": [
    "Write an Encoder Layer in Transformer from scratch **(no mask)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6c536bf8-9dce-480b-b5fa-540cbeeb3e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mha = MultiHeadAttention(d_model, n_heads)\n",
    "        self.norm_1 = ResidualLayerNorm(d_model, dropout=dropout)\n",
    "        self.feed_forward = PostionWiseFeedForward(d_model, n_heads)\n",
    "        self.norm_2 = ResidualLayerNorm(d_model, dropout=dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mha_output, mha_weights = self.mha(\n",
    "            pre_q=x, pre_k=x, pre_v=x\n",
    "        )        \n",
    "        norm_1 = self.norm_1(x=mha_output, residual=x)\n",
    "        ff = self.feed_forward(norm_1)\n",
    "        norm_2 = self.norm_2(ff, norm_1)\n",
    "        \n",
    "        return norm_2, mha_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b1e8196d-91a3-44a6-97e7-7aa10e925184",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = EncoderLayer(d_model=10, n_heads=2, d_ff=16, dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dc4f83a8-f437-45e9-8257-54738942adcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 10])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "12af9992-5d40-4993-a173-77801cd2a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, attention_weights = encoder_layer(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "20b30f11-6ccd-4bc3-b761-7b0dfc9404be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 10]), torch.Size([5, 2, 3, 3]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, attention_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0cd6cb-7b72-4a3b-96cc-f13a355cebeb",
   "metadata": {},
   "source": [
    "### Encoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31a23542-376e-426a-bf9c-4141f80b992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.arange(0, 30).reshape(6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbc4c69d-29e1-4f35-ba98-661c4fb1d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from foundation.transformer.encoder import EncoderLayer\n",
    "from foundation.transformer.embedding import TextEmbedding\n",
    "from foundation.transformer.positional_encoding import PositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "054d11f8-f1a3-4af3-9705-36d5d936948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, n_layers, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = TextEmbedding(\n",
    "            vocab_size = 1000,\n",
    "            d_model = d_model,\n",
    "            padding_idx = 0\n",
    "        )\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        self.encoders = nn.ModuleList([\n",
    "            EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # shape(x) = [batch_size x src_seq_len]\n",
    "        \n",
    "        # shape(embeddings) = [batch_size x src_seq_len x d_model]\n",
    "        embeddings = self.embedding(x)\n",
    "        # shape(encoding) = [batch_size x src_seq_len x d_model]\n",
    "        encoding = self.positional_encoding(embeddings)\n",
    "        \n",
    "        for encoder in self.encoders:\n",
    "            # shape(encoding) = [batch_size x src_seq_len x d_model]\n",
    "            # shape(encoder_attention_weights) = [batch_size x num_heads x src_seq_len x src_seq_len]\n",
    "            encoding, encoder_attention_weights = encoder(encoding)\n",
    "        \n",
    "        return encoding, encoder_attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b5179b2-dff9-4e35-a534-36857687e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "    d_model=10,\n",
    "    n_heads=2,\n",
    "    n_layers = 3,\n",
    "    d_ff=16,\n",
    "    dropout=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644f73d8-f243-4f08-ab56-eb73082104a7",
   "metadata": {},
   "source": [
    "`tokens` is a batch of `6` sentence, each sentence contains `5` words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d8f67af-e543-4c43-9db5-7f41eb0a4456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65db7b98-1652-41f1-b39e-4baa501783e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding, encoder_attention_weights = encoder(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52408f81-184b-4065-8352-02454a912ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 5, 10]), torch.Size([6, 2, 5, 5]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.shape, encoder_attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f39bb9-64e0-487d-8ec0-57271a8a218d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
